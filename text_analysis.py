# -*- coding: utf-8 -*-
"""text analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rl3ggtE9WonvmQ2ujzjs8WDnqwldydX_
"""

pip install transformers torch scikit-learn numpy

import torch
import numpy as np
from transformers import AutoTokenizer, AutoModel
from sklearn.metrics.pairwise import cosine_similarity
model_name = "sentence-transformers/all-MiniLM-L6-v2"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)
def mean_pooling(model_output, attention_mask):
    token_embeddings = model_output.last_hidden_state
    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(
        input_mask_expanded.sum(1), min=1e-9
    )
def get_sentence_embedding(sentence):
    encoded_input = tokenizer(
        sentence,
        padding=True,
        truncation=True,
        return_tensors='pt'
    )
    with torch.no_grad():
        model_output = model(**encoded_input)
    sentence_embedding = mean_pooling(
        model_output,
        encoded_input['attention_mask']
    )
    return sentence_embedding.numpy()
def text_similarity(text1, text2):
    emb1 = get_sentence_embedding(text1)
    emb2 = get_sentence_embedding(text2)
    similarity = cosine_similarity(emb1, emb2)
    return similarity[0][0]

# Get input from user
text_a = input("Enter the first sentence: ")
text_b = input("Enter the second sentence: ")

score = text_similarity(text_a, text_b)
print("Similarity Score:", score)

if score > 0.5:
    print("The sentences are similar.")
else:
    print("The sentences are not very similar.")