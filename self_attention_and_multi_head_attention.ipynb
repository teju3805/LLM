{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMH1NL5hRxxRo59YB/fmjwH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teju3805/LLM/blob/main/self_attention_and_multi_head_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M3gpSi9WVvE",
        "outputId": "be10284e-f9db-4e05-f301-d5d8dc088ef0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence: apple is a fruit\n",
            "\n",
            "========== Head 1 ==========\n",
            "\n",
            "Attention Scores:\n",
            "tensor([[2.9999, 1.9805, 2.6105, 1.5647],\n",
            "        [1.9805, 1.5090, 1.9128, 1.0383],\n",
            "        [2.6105, 1.9128, 2.4800, 1.4094],\n",
            "        [1.5647, 1.0383, 1.4094, 0.9747]])\n",
            "\n",
            "Attention Weights:\n",
            "tensor([[0.4393, 0.1585, 0.2976, 0.1046],\n",
            "        [0.3392, 0.2117, 0.3170, 0.1322],\n",
            "        [0.3737, 0.1860, 0.3279, 0.1124],\n",
            "        [0.3332, 0.1968, 0.2853, 0.1847]])\n",
            "\n",
            "Context Vectors:\n",
            "Context vector for 'apple' (Head 1):\n",
            "tensor([0.7742, 0.8796, 0.7171, 0.6039])\n",
            "Context vector for 'is' (Head 1):\n",
            "tensor([0.7357, 0.8625, 0.7139, 0.5503])\n",
            "Context vector for 'a' (Head 1):\n",
            "tensor([0.7536, 0.8716, 0.7231, 0.5716])\n",
            "Context vector for 'fruit' (Head 1):\n",
            "tensor([0.7284, 0.8565, 0.6792, 0.5370])\n",
            "\n",
            "========== Head 2 ==========\n",
            "\n",
            "Attention Scores:\n",
            "tensor([[1.1013, 1.2008, 0.5223, 0.7542],\n",
            "        [1.2008, 1.8853, 0.5782, 0.7227],\n",
            "        [0.5223, 0.5782, 0.2515, 0.3537],\n",
            "        [0.7542, 0.7227, 0.3537, 0.5870]])\n",
            "\n",
            "Attention Weights:\n",
            "tensor([[0.2966, 0.3276, 0.1662, 0.2096],\n",
            "        [0.2416, 0.4790, 0.1296, 0.1498],\n",
            "        [0.2728, 0.2885, 0.2081, 0.2305],\n",
            "        [0.2870, 0.2780, 0.1922, 0.2428]])\n",
            "\n",
            "Context Vectors:\n",
            "Context vector for 'apple' (Head 2):\n",
            "tensor([0.5291, 0.4283, 0.3891, 0.5316])\n",
            "Context vector for 'is' (Head 2):\n",
            "tensor([0.4883, 0.5065, 0.4680, 0.5956])\n",
            "Context vector for 'a' (Head 2):\n",
            "tensor([0.5254, 0.4023, 0.3597, 0.5065])\n",
            "Context vector for 'fruit' (Head 2):\n",
            "tensor([0.5350, 0.4001, 0.3557, 0.5043])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Take sentence from user\n",
        "text = input(\"Enter a sentence: \")\n",
        "\n",
        "# Tokenize sentence\n",
        "tokens = text.split()\n",
        "\n",
        "# Create embeddings\n",
        "embeddings = torch.rand(len(tokens), 8)\n",
        "\n",
        "num_heads = 2\n",
        "head_dim = embeddings.size(1) // num_heads\n",
        "\n",
        "for h in range(num_heads):\n",
        "    Q = embeddings[:, h*head_dim:(h+1)*head_dim]\n",
        "    K = Q\n",
        "    V = Q\n",
        "\n",
        "    # Attention scores\n",
        "    scores = torch.matmul(Q, K.T)\n",
        "\n",
        "    # Attention weights\n",
        "    weights = F.softmax(scores, dim=1)\n",
        "\n",
        "    # Context vectors\n",
        "    context_vectors = torch.matmul(weights, V)\n",
        "\n",
        "    print(f\"\\n========== Head {h+1} ==========\")\n",
        "\n",
        "    print(\"\\nAttention Scores:\")\n",
        "    print(scores)\n",
        "\n",
        "    print(\"\\nAttention Weights:\")\n",
        "    print(weights)\n",
        "\n",
        "    print(\"\\nContext Vectors:\")\n",
        "    for i, word in enumerate(tokens):\n",
        "        print(f\"Context vector for '{word}' (Head {h+1}):\")\n",
        "        print(context_vectors[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Take sentence from user\n",
        "text = input(\"Enter a sentence: \")\n",
        "\n",
        "# Tokenize sentence\n",
        "tokens = text.split()\n",
        "\n",
        "# Create random embeddings for each token\n",
        "embeddings = torch.rand(len(tokens), 8)\n",
        "\n",
        "# Query, Key, Value matrices\n",
        "Q = embeddings\n",
        "K = embeddings\n",
        "V = embeddings\n",
        "\n",
        "# Compute attention scores (Q Ã— K^T)\n",
        "attention_scores = torch.matmul(Q, K.T)\n",
        "\n",
        "# Normalize scores using softmax\n",
        "attention_weights = F.softmax(attention_scores, dim=1)\n",
        "\n",
        "# Compute context vectors (Attention Output)\n",
        "context_vectors = torch.matmul(attention_weights, V)\n",
        "\n",
        "# Print attention scores\n",
        "print(\"\\nAttention Scores:\")\n",
        "print(attention_scores)\n",
        "\n",
        "# Print attention weights\n",
        "print(\"\\nAttention Weights:\")\n",
        "print(attention_weights)\n",
        "\n",
        "# Print context vector for each word\n",
        "print(\"\\nContext Vectors for Each Word:\")\n",
        "for i, word in enumerate(tokens):\n",
        "    print(f\"Context vector for '{word}':\")\n",
        "    print(context_vectors[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRSf3jKnWeAX",
        "outputId": "6cec9c3e-274a-4a2a-a8ab-85a7c13fa10b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence: apple is a fruit\n",
            "\n",
            "Attention Scores:\n",
            "tensor([[1.6416, 1.3058, 1.1515, 1.1577],\n",
            "        [1.3058, 2.6838, 1.3656, 1.8483],\n",
            "        [1.1515, 1.3656, 1.9442, 0.9666],\n",
            "        [1.1577, 1.8483, 0.9666, 2.0680]])\n",
            "\n",
            "Attention Weights:\n",
            "tensor([[0.3397, 0.2428, 0.2081, 0.2094],\n",
            "        [0.1291, 0.5119, 0.1370, 0.2220],\n",
            "        [0.1894, 0.2346, 0.4185, 0.1574],\n",
            "        [0.1586, 0.3163, 0.1310, 0.3941]])\n",
            "\n",
            "Context Vectors for Each Word:\n",
            "Context vector for 'apple':\n",
            "tensor([0.3739, 0.3254, 0.4114, 0.5767, 0.4638, 0.4534, 0.3282, 0.4469])\n",
            "Context vector for 'is':\n",
            "tensor([0.4812, 0.4752, 0.4014, 0.7757, 0.2962, 0.5208, 0.3443, 0.3484])\n",
            "Context vector for 'a':\n",
            "tensor([0.3402, 0.2678, 0.4960, 0.4890, 0.4068, 0.6220, 0.3355, 0.4010])\n",
            "Context vector for 'fruit':\n",
            "tensor([0.4879, 0.3371, 0.3322, 0.7563, 0.3271, 0.4401, 0.4020, 0.4067])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p7LWwN9-WvOD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}